{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MAC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBBPZDxlzLi_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.losses as losses\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "!pip install -q -U keras-tuner\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "import time\n",
        "LOG_DIR = f\"{int(time.time())}\"\n",
        "from keras.layers import BatchNormalization\n",
        "from tempfile import TemporaryFile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow.keras.regularizers as regularizers\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.patches as patches\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from google.colab import drive\n",
        "import time\n",
        "drive.mount('/content/drive/')\n",
        "dataset_dir = \"/content/drive/My Drive/dataset_aircraft\"\n",
        " \n",
        "training_data = []\n",
        "test_data = []\n",
        "RESIZE_VALUE = 130\n",
        "root_path = \"/content/drive/My Drive/dataset_aircraft/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTMV6ekteaG4"
      },
      "source": [
        "drive.mount('/content/drive/')\n",
        "dataset_dir = \"/content/drive/My Drive/dataset_aircraft\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ3j-wDnnBmi"
      },
      "source": [
        "def image_process():\n",
        "  #image processing (dataset image randomizer)\n",
        "  plane = \"c/\"\n",
        "  datagen = ImageDataGenerator(\n",
        "          rotation_range=360,\n",
        "          width_shift_range=0,\n",
        "          height_shift_range=0,\n",
        "          shear_range=0,\n",
        "          zoom_range=0.0,\n",
        "          horizontal_flip=True,\n",
        "          fill_mode='nearest')\n",
        "  \n",
        "  selected_path = root_path+plane\n",
        "  for img_ in os.listdir(selected_path):\n",
        "    img = load_img(selected_path+img_)  # this is a PIL image\n",
        "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "    # the .flow() command below generates batches of randomly transformed images\n",
        "    # and saves the results to the `preview/` directory\n",
        "    i = 0\n",
        "    for batch in datagen.flow(x, batch_size=1,\n",
        "                              save_to_dir=root_path+plane, save_prefix=img_, save_format='jpeg'):\n",
        "        i += 1\n",
        "        if i > 20: # the number of image generation (amendments) per selected picture\n",
        "            break\n",
        "image_process()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBYS_Q7wzaeO"
      },
      "source": [
        "# outputs the names of the files currently in the google drive file (dataset) \n",
        "types_path = \"/content/drive/My Drive/dataset_aircraft/TYPE-NAMES.txt\"\n",
        "aircraft_types = []\n",
        "f = open(types_path, \"r\")\n",
        "for types in f.read().split():\n",
        "  aircraft_types.append(types.replace('\"',''))\n",
        "print(len(aircraft_types))\n",
        "f.close()\n",
        "print(\"Selected aircraft files:\",aircraft_types)\n",
        "print(\"Files in dataset (Google drive):\",os.listdir(root_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfvpfKSAcbxG"
      },
      "source": [
        "def create_training_data():\n",
        "    # function iterates through each file in the google drive dataset and converts each image into an array\n",
        "  for type in aircraft_types:\n",
        "    selected_path = root_path + type\n",
        "    class_num = aircraft_types.index(type)\n",
        "    for img in os.listdir(selected_path):\n",
        "      try:\n",
        "        image = Image.open(os.path.join(selected_path,img))\n",
        "        img_array = np.array(image)\n",
        "        aircraft_img = cv2.resize(img_array, (RESIZE_VALUE, RESIZE_VALUE))\n",
        "        training_data.append([aircraft_img, class_num])\n",
        "      except Exception as e:\n",
        "        print(\"error:\",selected_path,image)\n",
        " \n",
        "create_training_data()\n",
        "random.shuffle(training_data)\n",
        "print(len(training_data))\n",
        "print(training_data[0][1])\n",
        "plt.imshow(training_data[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYF0U-hgchzb"
      },
      "source": [
        "# saves all generated arrays of images to a file\n",
        "np.savez_compressed(root_path+'primary_training_dataset.npz', a=training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxKXkcrZ5flI",
        "outputId": "025c6bd0-e7cb-44ea-a0eb-11ddeee9946b"
      },
      "source": [
        "def load_training_data():\n",
        "  #LOAD TRAINING DATA INTO ARRAY FROM FILE\n",
        "  loaded = np.load(root_path+\"primary_training_dataset.npz\", allow_pickle=True)\n",
        "  training_data = loaded['a']\n",
        "  for x in range(len(training_data)):\n",
        "    if (training_data[x][0].shape[2] == 4):\n",
        "      training_data[x][0] = cv2.cvtColor(training_data[x][0], cv2.COLOR_BGRA2BGR)\n",
        "  return training_data\n",
        "training_data = load_training_data()\n",
        "random.shuffle(training_data)\n",
        "print(len(training_data))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOhCn2Dfzlvj"
      },
      "source": [
        "def load_testing():\n",
        "  #LOAD TESTING DATA INTO ARRAY FROM FILE\n",
        "  loaded = np.load(root_path+\"primary_training_dataset.npz\", allow_pickle=True)\n",
        "  training_data = loaded['a']\n",
        "  for x in range(len(training_data)):\n",
        "    if (training_data[x][0].shape[2] == 4):\n",
        "      training_data[x][0] = cv2.cvtColor(training_data[x][0], cv2.COLOR_BGRA2BGR)\n",
        "  return training_data\n",
        "testing_data = load_testing()\n",
        "random.shuffle(testing_data)\n",
        "print(len(testing_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-qmz7-9zy--"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        " \n",
        "#x_test = []\n",
        "#y_test = []\n",
        " \n",
        "#for data, label in testing_data:\n",
        "#  x_test.append(data)\n",
        "#  y_test.append(label)\n",
        " \n",
        "for data, label in training_data:\n",
        "  x_train.append(data)\n",
        "  y_train.append(label)\n",
        " \n",
        "x_train = np.asarray(x_train)\n",
        "x_train = np.array(x_train).reshape(-1, RESIZE_VALUE, RESIZE_VALUE, 3)\n",
        "y_train = np.asarray(y_train)\n",
        " \n",
        "#x_test = np.asarray(x_test)\n",
        "#x_test = np.array(x_test).reshape(-1, RESIZE_VALUE, RESIZE_VALUE, 3)\n",
        "#y_test = np.asarray(y_test)\n",
        "\n",
        "x_train = x_train / 255\n",
        "#x_test = x_test / 255\n",
        "print(len(x_train))\n",
        "#print(len(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PGRuzpvz2bq"
      },
      "source": [
        "\n",
        "model = keras.models.load_model(root_path+\"Model V6\")"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChltQUnNLDjK"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1EA_eWP7vfR"
      },
      "source": [
        "def build_model_MAC():\n",
        "    # main model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), input_shape = (RESIZE_VALUE,RESIZE_VALUE,3)))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(450))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(.65))\n",
        "    \n",
        "    model.add(Dense(len(aircraft_types)))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=opt,\n",
        "                    metrics=['acc'])\n",
        "  \n",
        "    return model\n",
        "\n",
        "model = build_model_MAC()\n",
        "epochs = 30\n",
        "x = np.arange(epochs) + 1\n",
        "history_ = model.fit(x_train, y_train, epochs=epochs, validation_split=.30, batch_size=64)\n",
        "plt.plot(x,history_.history['acc'])\n",
        "plt.plot(x,history_.history['val_acc'])\n",
        "plt.xlabel(\"Epochs\");\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['Training Accuacy', 'Cross Validation Accuracy']);\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x,history_.history['loss'])\n",
        "ax.plot(x,history_.history['val_loss'])\n",
        "plt.xlabel(\"Epochs\");\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(['Training Loss', 'Cross Validation Loss']);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt_TtM2Dx1MN"
      },
      "source": [
        "model.save(root_path+\"Model V6\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhG6eJdgHNBC"
      },
      "source": [
        "def testSingleAircraft():\n",
        "    # function takes a single image of an aircraft and classifies the aircraft category\n",
        "    img = \"C-17.JPG\"\n",
        "    image = Image.open(os.path.join(root_path+\"/Testing Images/\",img))\n",
        "    img_array = np.array(image)\n",
        "    aircraft_img = cv2.resize(img_array, (RESIZE_VALUE, RESIZE_VALUE))\n",
        "    patch = np.expand_dims(aircraft_img, axis=0)\n",
        "    plt.imshow(aircraft_img)\n",
        "    x = model.predict_classes(patch)\n",
        "    print (\"True value:\", img)\n",
        "    print(\"Identified as:\",aircraft_types[x[0]],\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUotZsyVHPNg"
      },
      "source": [
        "def testMultipleAircraft():\n",
        "    #function takes a wide picture consisting of multiple aircrafts and marks aircrafts\n",
        "    img = \"1.JPG\"\n",
        "    image = Image.open(os.path.join(root_path+\"/Testing Images/\",img))\n",
        "    img_array = np.array(image)\n",
        "    img_shape = img_array.shape\n",
        "    aircraft_img = cv2.resize(img_array, (img_shape[1], img_shape[0]))\n",
        "    test_img =  cv2.cvtColor(aircraft_img, cv2.COLOR_BGRA2BGR)\n",
        "    plt.imshow(test_img)\n",
        "    ax = plt.gca()\n",
        "    pred_dist = np.arange(len(aircraft_types))\n",
        "    classif = []\n",
        "    detectCount = 0;\n",
        "    counter = 0\n",
        "    # set length and width of patch\n",
        "    length = 80\n",
        "    width = 80\n",
        "    # do not show list\n",
        "    dshow = [\"BareLand\"]\n",
        "    # iterate through the entire image and predict each patch\n",
        "    for i in range(0,test_img.shape[0], 30):\n",
        "      for j in range (0,test_img.shape[1], 30):\n",
        "        if (j+length < test_img.shape[1] and i+width < test_img.shape[0]):\n",
        "          raw_patch = test_img[i:i+length, j:j+width]\n",
        "          aircraft_img = cv2.resize(raw_patch, (RESIZE_VALUE, RESIZE_VALUE))\n",
        "          patch = np.expand_dims(aircraft_img, axis=0)\n",
        "          ident = model.predict_classes(patch)\n",
        "          pred_dist[ident[0]] += 1\n",
        "          u = aircraft_types[ident[0]]\n",
        "          # do not mark patch if patch is classified as bareland (background)\n",
        "          if (u not in dshow):\n",
        "            # mark the identified patch with a red rectangle ROI, region of interest\n",
        "            ax.add_patch(patches.Rectangle((j, i), (j+length)-j, (i+width)-i, facecolor='none',edgecolor='red', linewidth=.5))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "testMultipleAircraft()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwn22NtlSPXT"
      },
      "source": [
        "def build_model(hp):\n",
        "    # this function uses hyperparameter method provided by keras to fine tune a model \n",
        "  model = Sequential()\n",
        " \n",
        "  model.add(Conv2D(hp.Int('conv1', 32,64,12), (3, 3), input_shape = (RESIZE_VALUE,RESIZE_VALUE,3)))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  model.add(Conv2D(hp.Int('conv2', 32,64,12), (3, 3)))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  model.add(Conv2D(hp.Int('conv3', 32,64,12), (3, 3)))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "  model.add(Flatten())\n",
        "  \n",
        "  model.add(Dense(hp.Int('dense1', 400,1000,100)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(\n",
        "            Dropout(rate=hp.Float(\n",
        "                'dropout_1',\n",
        "                min_value=0.40,\n",
        "                max_value=0.7,\n",
        "                default=0.50,\n",
        "                step=0.10,\n",
        "            )))\n",
        " \n",
        "  model.add(Dense(len(aircraft_types)))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=opt,\n",
        "                    metrics=['acc'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def tuner():\n",
        "    tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_acc\",\n",
        "    max_trials=20,\n",
        "    executions_per_trial = 1,\n",
        "    directory = LOG_DIR\n",
        "    )\n",
        "\n",
        "    tuner.search(x=x_train,\n",
        "             y=y_train,\n",
        "             epochs=50,\n",
        "             batch_size=80,\n",
        "             validation_split=.35)\n",
        "\n",
        "#tuner()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}